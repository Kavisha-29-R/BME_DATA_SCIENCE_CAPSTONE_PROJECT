{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09ec6e1",
   "metadata": {},
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d98eb",
   "metadata": {},
   "source": [
    "This notebook explores the dataset:\n",
    "\n",
    "Regulation of Brain Cognitive States through Auditory, Gustatory, and Olfactory Stimulation with Wearable Monitoring (v1.0.0)\n",
    "from PhysioNet. https://physionet.org/content/brain-wearable-monitoring/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea01fd",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "This dataset encompasses the outcomes of two distinct experiments, with each containing participants' correct/incorrect responses, accompanied by their response times, documented as 'n_back_responses'. Alongside these behavioral responses, the dataset incorporates physiological measurements collected from two Empatica devices, each affixed to either hand, as well as data obtained from a muse headband. \n",
    "\n",
    "To present the data in a structured manner, each participant's data is contained within a designated folder, numbered sequentially from A1 to A10 in Experiment 1, and B1 to B10 in Experiment 2. The dataset also includes the data from participants who were excluded for further analysis in [1]. Their folder names are named 'Excluded_ID_number' [1]. Their ID numbers are according to those presented in supplementary materials in [1]. The column “Start_time_unix” shows the initial time of the recording expressed as UNIX timestamp in UTC.  \n",
    "\n",
    "The experiment settings and behavioral signals can be found in the ‘n_back_responses.csv’ file. The .csv file is in the following format:\n",
    "\n",
    "The “ExperimentName” specifies the experiment of the study.\n",
    "The “Instruction” specifies the presented n-back task at each trial.\n",
    "The “Running [Block]” displays the applied actuator within each session.\n",
    "In the designed n-back experiments, subjects were shown trials of stimulus (500 ms) along with a plus sign (fixation cross) for their response (1500 ms). The behavioral signals including the reaction time (RT) and correct/incorrect response are stored under the “Stimulus” and “Fixation” categories.\n",
    "\n",
    "In experiment 1, the reaction times (milliseconds) associated with session 1 to session 4 are stored within “Fixation101.RT” to “Fixation104.RT” and “Stimulus101.RT” to “Stimulus104.RT”. The binary correct/incorrect responses associated with session 1 to session 4 are stored within “Fixation101.ACC” to “Fixation104.ACC” and “Stimulus101.ACC” to “Stimulus104.ACC”.\n",
    "\n",
    "In experiment 2, the reaction times (milliseconds) associated with session 1 to session 3 are stored within “Fixation101.RT” to “Fixation103.RT” and “Stimulus101.RT” to “Stimulus103.RT”. The binary correct/incorrect responses associated with session 1 to session 3 are stored within “Fixation101.ACC” to “Fixation103.ACC” and “Stimulus101.ACC” to “Stimulus103.ACC”.\n",
    "\n",
    "The EEG signals recorded from the Muse headband are also included in the dataset as 'EEG_recording.csv'. They include EEG channels from four locations: TP9, AF7, AF8, and TP10. The 2016 model Muse (MU-02) can also output RAW EEG data at 256Hz as well as being able to output RAW EEG from the right ear USB Auxiliary connector (named Right AUX in the csv files). The column (timestamps) shows the data points in UNIX format. EEG measurements are labeled as TP9, AF7, AF8, TP10, Right AUX.\n",
    "\n",
    "The Empatica data encompasses a range of physiological aspects, including participants' electrodermal activity (EDA), heart rate (HR), blood volume pulses (BVP), skin surface temperature, Photoplethysmography (PPG), and 3-axis accelerometer data. These data types are stored as separate CSV files: 'EDA.csv', 'TEMP.csv', 'ACC.csv', 'BVP.csv', 'HR.csv', 'IBI.csv', and 'tags.csv'. Data recorded by Empatica wristbands from Left and Right hands are each represented by their own distinct CSV files, encompassing the following attributes:\n",
    "\n",
    "- 'Left_EDA.csv' and 'Right_EDA.csv'\n",
    "- 'Left_TEMP.csv' and 'Right_TEMP.csv'\n",
    "- 'Left_ACC.csv' and 'Right_ACC.csv'\n",
    "- 'Left_BVP.csv' and 'Right_BVP.csv'\n",
    "- 'Left_HR.csv' and 'Right_HR.csv'\n",
    "- 'Left_IBI.csv' and 'Right_IBI.csv'\n",
    "- 'Left_tags.csv' and 'Right_tags.csv'\n",
    "\n",
    "For clarity, a concise summary of the contents of the different data files is provided below:\n",
    "\n",
    "- EDA: Measurements from the electrodermal activity (EDA) sensor expressed as micro siemens (μS). Values in the first column (EDA) show the EDA values. The column (start_time_unix) shows the initial time of the recording expressed as UNIX timestamp in UTC. The column (sampling_rate) shows the sample rate expressed in Hz.\n",
    "- TEMP: Skin temperature (TEMP) measured from temperature sensor expressed degrees on the Celsius (°C) scale. Values in the first column (TEMP) show the TEMP values. The column (start_time_unix) shows the initial time of the recording expressed as UNIX timestamp in UTC. The column (sampling_rate) shows the sample rate expressed in Hz.\n",
    "- ACC: Data from 3-axis accelerometer sensor. The accelerometer is configured to measure acceleration in the range [-2g, 2g]. Therefore, the unit in this file is 1/64g. Data from x, y, and z axis are labeled respectively (i.e., ACC_X, ACC_Y, and ACC_Z).  The column (start_time_unix) shows the initial time of the recording expressed as UNIX timestamp in UTC. The column (sampling_rate) shows the sample rate expressed in Hz.\n",
    "- BVP: Blood volume pulses (BVP) measured from a photoplethysmograph. Values in the first column (BVP) show the BVP values. The column (start_time_unix) shows the initial time of the recording expressed as UNIX timestamp in UTC. The column (sampling_rate) shows the sample rate expressed in Hz.\n",
    "- HR: Average heart rate (HR) extracted from the BVP signal. Values in the first column (HR) show the HR values. The column (start_time_unix) shows the initial time of the recording expressed as UNIX timestamp in UTC. The column (sampling_rate) shows the sample rate expressed in Hz.\n",
    "- IBI: Time between individuals heart beats extracted from the BVP signal. The first column (IBI_time) shows the time (with respect to the initial time) of the detected inter-beat interval expressed in seconds (s). The second column (IBI_intervals) shows the duration in seconds (s) of the detected inter-beat interval (i.e., the distance in seconds from the previous beat). No sample rate is needed for this file.\n",
    "- tags: Event mark times in each Empatica device. Each row corresponds to a physical button press on the device; at the same time as the status LED is first illuminated. The time is expressed as a UNIX timestamp in UTC, and it is synchronized with the initial time of the recordings indicated in the related data files from the corresponding session.\n",
    "Due to the inadvertent receipt of certain tags during experiments, the correct and unified tags are also included as 'tags.csv'.\n",
    "\n",
    "[1] Fekri Azgomi, Hamid, et al. \"Regulation of brain cognitive states through auditory, gustatory, and olfactory stimulation with wearable monitoring.\" Scientific Reports 13.1 (2023): 12399. https://www.nature.com/articles/s41598-023-37829-z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e9702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.signal import welch, find_peaks\n",
    "from scipy.stats import iqr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fef82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions (as specified in data description):\n",
    "# - Each participant folder (A1..A10, B1..B10, Excluded_...) contains:\n",
    "#     n_back_responses.csv\n",
    "#     EEG_recordings.csv\n",
    "#     Left_ACC.csv, Right_ACC.csv, Left_BVP.csv, Right_BVP.csv, Left_EDA.csv, Right_EDA.csv, Left_HR.csv, Right_HR.csv,\n",
    "#     Left_IBI.csv, Right_IBI.csv, Left_TEMP.csv, Right_TEMP.csv, tags.csv (or Left_tags/Right_tags)\n",
    "# - Empatica CSVs have columns (ACC_X,ACC_Y,ACC_Z,start_time_unix,sampling_rate, etc.)\n",
    "# - Muse EEG CSV has 'timestamps' (UNIX seconds or ms) and channels TP9, AF7, AF8, TP10, Right AUX\n",
    "# - Trial structure: trials spaced every 2.0 s per session block (500 ms stimulus + 1500 ms fixation)\n",
    "# - Reaction times in Stimulus###.RT / Fixation###.RT are in milliseconds (ms) and ACC columns indicate correctness (1==correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc0f03",
   "metadata": {},
   "source": [
    "Data stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f9532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- dataset folder ----------\n",
    "BASE_PATH = Path(r\"C:\\Users\\Kavisha\\OneDrive - Johns Hopkins\\EN.585.771_BME_DATASCIENCE\\Capstone_Project\\Data\\Brain_Cognitive_States_Data\")\n",
    "EXP1 = BASE_PATH / \"Experiment_1\"\n",
    "EXP2 = BASE_PATH / \"Experiment_2\"\n",
    "OUT_DIR = BASE_PATH / \"processed_features_final\"\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a8104",
   "metadata": {},
   "source": [
    "Functions for handling files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac7f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_empatica_file(path, kind):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    if 'start_time_unix' not in [c.lower() for c in df.columns]:\n",
    "        raise ValueError(f\"{path.name} missing start_time_unix column\")\n",
    "    # ensure column names as original (case-sensitive) accessible\n",
    "    # find the actual column names for start_time_unix and sampling_rate if they have different case\n",
    "    start_col = next(c for c in df.columns if c.lower() == 'start_time_unix')\n",
    "    sr_col = next((c for c in df.columns if c.lower() == 'sampling_rate'), None)\n",
    "    st = float(df[start_col].dropna().iloc[0])\n",
    "    sr = float(df[sr_col].dropna().iloc[0]) if sr_col else None\n",
    "\n",
    "    if kind.lower() == 'acc':\n",
    "        # expect ACC_X,ACC_Y,ACC_Z present\n",
    "        # create time axis from index and sampling rate\n",
    "        if sr is None:\n",
    "            raise ValueError(f\"ACC file {path} missing sampling_rate\")\n",
    "        n = len(df)\n",
    "        times = st + (np.arange(n) / sr)\n",
    "        out = df.copy().reset_index(drop=True)\n",
    "        out['time_s'] = times\n",
    "        out = out.set_index('time_s').sort_index()\n",
    "        # keep ACC_X/Y/Z\n",
    "        cols = [c for c in out.columns if c.lower() in ('acc_x','acc_y','acc_z')]\n",
    "        return out[cols].astype(float)\n",
    "    elif kind.lower() in ('bvp','eda','hr','temp'):\n",
    "        if sr is None:\n",
    "            raise ValueError(f\"{path} missing sampling_rate\")\n",
    "        n = len(df)\n",
    "        times = st + (np.arange(n) / sr)\n",
    "        # pick the measurement column (first column that's not start_time_unix or sampling_rate)\n",
    "        meas_col = next((c for c in df.columns if c.lower() not in ('start_time_unix','sampling_rate')), df.columns[0])\n",
    "        out = pd.DataFrame({meas_col: df[meas_col].values}, index=times)\n",
    "        out.index.name = 'time_s'\n",
    "        return out.astype(float)\n",
    "    elif kind.lower() == 'ibi':\n",
    "        # expects IBI_time (s) and IBI_intervals (s)\n",
    "        # absolute times = start_time_unix + IBI_time\n",
    "        ibi_time_col = next((c for c in df.columns if c.lower() == 'ibi_time'), None)\n",
    "        ibi_int_col = next((c for c in df.columns if 'ibi_intervals' in c.lower() or 'ibi_interval' in c.lower()), None)\n",
    "        if ibi_time_col is None:\n",
    "            # try lowercase names\n",
    "            raise ValueError(f\"IBI file {path} missing IBI_time column\")\n",
    "        abs_times = st + df[ibi_time_col].astype(float).values\n",
    "        out = pd.DataFrame({'IBI_interval': df[ibi_int_col].astype(float).values}, index=abs_times)\n",
    "        out.index.name = 'time_s'\n",
    "        return out\n",
    "    else:\n",
    "        raise ValueError(\"Unknown empatica kind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ed2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Behavior parsing (uses the actual Stimulus###.RT & Fixation###.RT style columns) ----------\n",
    "def load_behavior(participant_folder):\n",
    "    bf = participant_folder / 'n_back_responses.csv'\n",
    "    if not bf.exists():\n",
    "        raise FileNotFoundError(f\"Behavior file missing for {participant_folder}\")\n",
    "    df = pd.read_csv(bf)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a74487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_tags(participant_folder):\n",
    "    # prefer unified tags.csv, else Left_tags or Right_tags, else None\n",
    "    for fname in ['tags.csv','Tags.csv','left_tags.csv','Left_tags.csv','right_tags.csv','Right_tags.csv']:\n",
    "        p = participant_folder / fname\n",
    "        if p.exists():\n",
    "            arr = pd.read_csv(p, header=None).iloc[:,0].astype(float).tolist()\n",
    "            return arr\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ccddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_behavior_events(behavior_df, tags_list, experiment_label):\n",
    "    \"\"\"\n",
    "    Convert stimulus/fixation RT & ACC columns into event rows with absolute timestamps (seconds).\n",
    "    - behavior_df: per-participant n_back_responses.csv\n",
    "    - tags_list: list of session start UNIX times in seconds (tags.csv)\n",
    "    - experiment_label: 'Experiment_1' or 'Experiment_2'\n",
    "    \n",
    "    Returns DataFrame with columns:\n",
    "    event_time_s, trial_type, session_idx, trial_idx, RT_s, ACC\n",
    "    \"\"\"\n",
    "    # ---------------------------\n",
    "    # 1. Identify session type column\n",
    "    # ---------------------------\n",
    "    if \"Running [Block]\" in behavior_df.columns:\n",
    "        block_col = \"Running [Block]\"\n",
    "    elif \"Running[Block]\" in behavior_df.columns:\n",
    "        block_col = \"Running[Block]\"\n",
    "    else:\n",
    "        block_col = None\n",
    "\n",
    "    if behavior_df is None or behavior_df.shape[0] == 0:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'event_time_s', 'trial_type', 'session_idx', 'trial_idx',\n",
    "            'RT_s', 'ACC', 'session_type'\n",
    "        ])\n",
    "        \n",
    "    # ---------------------------\n",
    "    # 2. RT and ACC column detection\n",
    "    # ---------------------------\n",
    "    stim_rt_cols = sorted([c for c in behavior_df.columns \n",
    "                           if re.match(r'(?i)stimulus[0-9]{3}\\.RT$', c) or re.match(r'(?i)stimulus[0-9]{3}_RT$', c)])\n",
    "\n",
    "    stim_acc_cols = sorted([c for c in behavior_df.columns \n",
    "                            if re.match(r'(?i)stimulus[0-9]{3}\\.ACC$', c) or re.match(r'(?i)stimulus[0-9]{3}_ACC$', c)])\n",
    "\n",
    "    fix_rt_cols = sorted([c for c in behavior_df.columns \n",
    "                          if re.match(r'(?i)fixation[0-9]{3}\\.RT$', c) or re.match(r'(?i)fixation[0-9]{3}_RT$', c)])\n",
    "\n",
    "    fix_acc_cols = sorted([c for c in behavior_df.columns \n",
    "                           if re.match(r'(?i)fixation[0-9]{3}\\.ACC$', c) or re.match(r'(?i)fixation[0-9]{3}_ACC$', c)])\n",
    "       \n",
    "    # ---------------------------\n",
    "    # 3. Build maps for each session code\n",
    "    # ---------------------------\n",
    "    stim_map = {}\n",
    "    for c in stim_rt_cols:\n",
    "        code = int(re.search(r'([0-9]{3})', c).group(1))\n",
    "        stim_map.setdefault(code, {})['rt'] = behavior_df[c].values\n",
    "\n",
    "    for c in stim_acc_cols:\n",
    "        code = int(re.search(r'([0-9]{3})', c).group(1))\n",
    "        stim_map.setdefault(code, {})['acc'] = behavior_df[c].values\n",
    "\n",
    "    fix_map = {}\n",
    "    for c in fix_rt_cols:\n",
    "        code = int(re.search(r'([0-9]{3})', c).group(1))\n",
    "        fix_map.setdefault(code, {})['rt'] = behavior_df[c].values\n",
    "\n",
    "    for c in fix_acc_cols:\n",
    "        code = int(re.search(r'([0-9]{3})', c).group(1))\n",
    "        fix_map.setdefault(code, {})['acc'] = behavior_df[c].values\n",
    "        \n",
    "    # ---------------------------\n",
    "    # 4. Expected sessions (Exp1 = 4, Exp2 = 3)\n",
    "    # ---------------------------\n",
    "    if '1' in str(experiment_label):\n",
    "        expected_codes = [101, 102, 103, 104]\n",
    "    else:\n",
    "        expected_codes = [101, 102, 103]\n",
    "        \n",
    "    # ---------------------------\n",
    "    # 5. Session start timestamps\n",
    "    # ---------------------------\n",
    "    if len(tags_list) == 0:\n",
    "        st_col = next((c for c in behavior_df.columns if c.lower() == 'start_time_unix'), None)\n",
    "        if st_col:\n",
    "            base_time = float(behavior_df[st_col].dropna().iloc[0])\n",
    "            tags_list = [base_time + i*1.0 for i in range(len(expected_codes))]\n",
    "        else:\n",
    "            tags_list = [0.0] * len(expected_codes)\n",
    "            \n",
    "    # ---------------------------\n",
    "    # 6. Build event rows\n",
    "    # ---------------------------\n",
    "    events = []\n",
    "    for sidx, code in enumerate(expected_codes):\n",
    "\n",
    "        session_start = tags_list[sidx] if sidx < len(tags_list) else tags_list[-1]\n",
    "\n",
    "        stim_entry = stim_map.get(code, {})\n",
    "        fix_entry = fix_map.get(code, {})\n",
    "\n",
    "        n_trials = len(stim_entry.get('rt', [])) if 'rt' in stim_entry \\\n",
    "                   else len(fix_entry.get('rt', [])) if 'rt' in fix_entry else 0\n",
    "\n",
    "        for j in range(n_trials):\n",
    "\n",
    "            # Extract session type (same row for stimulus & fixation)\n",
    "            session_type_val = None\n",
    "            if block_col is not None and j < len(behavior_df):\n",
    "                session_type_val = behavior_df[block_col].iloc[j]\n",
    "\n",
    "            # ------------------ Stimulus ------------------\n",
    "            stim_onset = session_start + j * 2.0\n",
    "\n",
    "            # RT\n",
    "            rt_s = None\n",
    "            if 'rt' in stim_entry and j < len(stim_entry['rt']):\n",
    "                try:\n",
    "                    rt_ms = float(stim_entry['rt'][j])\n",
    "                    rt_s = rt_ms / 1000.0 if (rt_ms > 0 and np.isfinite(rt_ms)) else None\n",
    "                except:\n",
    "                    rt_s = None\n",
    "\n",
    "            # ACC\n",
    "            acc_s = None\n",
    "            if 'acc' in stim_entry and j < len(stim_entry['acc']):\n",
    "                try:\n",
    "                    acc_s = int(stim_entry['acc'][j])\n",
    "                except:\n",
    "                    acc_s = None\n",
    "\n",
    "            events.append({\n",
    "                'event_time_s': stim_onset + rt_s if rt_s else stim_onset,\n",
    "                'trial_type': 'stimulus',\n",
    "                'session_idx': sidx+1,\n",
    "                'trial_idx': j+1,\n",
    "                'RT_s': rt_s if rt_s else np.nan,\n",
    "                'ACC': acc_s,\n",
    "                'session_type': session_type_val,\n",
    "            })\n",
    "\n",
    "            # ------------------ Fixation ------------------\n",
    "            fix_onset = stim_onset + 0.5\n",
    "\n",
    "            rt_f = None\n",
    "            if 'rt' in fix_entry and j < len(fix_entry['rt']):\n",
    "                try:\n",
    "                    rt_ms = float(fix_entry['rt'][j])\n",
    "                    rt_f = rt_ms / 1000.0 if (rt_ms > 0 and np.isfinite(rt_ms)) else None\n",
    "                except:\n",
    "                    rt_f = None\n",
    "\n",
    "            acc_f = None\n",
    "            if 'acc' in fix_entry and j < len(fix_entry['acc']):\n",
    "                try:\n",
    "                    acc_f = int(fix_entry['acc'][j])\n",
    "                except:\n",
    "                    acc_f = None\n",
    "\n",
    "            events.append({\n",
    "                'event_time_s': fix_onset + rt_f if rt_f else fix_onset,\n",
    "                'trial_type': 'fixation',\n",
    "                'session_idx': sidx+1,\n",
    "                'trial_idx': j+1,\n",
    "                'RT_s': rt_f if rt_f else np.nan,\n",
    "                'ACC': acc_f,\n",
    "                'session_type': session_type_val,\n",
    "            })\n",
    "            \n",
    "    # ---------------------------\n",
    "    # 7. Final dataframe\n",
    "    # ---------------------------\n",
    "    evdf = pd.DataFrame(events)\n",
    "    evdf = evdf.sort_values('event_time_s').reset_index(drop=True)\n",
    "\n",
    "    return evdf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4db045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Feature extraction ----------\n",
    "def bandpower(arr, fs, band):\n",
    "    if len(arr) < 4 or np.all(np.isnan(arr)):\n",
    "        return np.nan\n",
    "    f,Pxx = welch(arr, fs=fs, nperseg=min(256, len(arr)))\n",
    "    mask = (f>=band[0]) & (f<=band[1])\n",
    "    if mask.sum()==0:\n",
    "        return 0.0\n",
    "    return np.trapz(Pxx[mask], f[mask])\n",
    "\n",
    "BANDS = {'delta':(1,4),'theta':(4,8),'alpha':(8,13),'beta':(13,30),'gamma':(30,45)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2dc820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_magnitude(acc_df):\n",
    "    arr = acc_df[['ACC_X','ACC_Y','ACC_Z']].astype(float).values\n",
    "    return np.linalg.norm(arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4b2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ibi_features(ibi_df):\n",
    "    arr = ibi_df['IBI_interval'].dropna().values\n",
    "    if len(arr)==0:\n",
    "        return {'ibi_count':0,'ibi_sdnn':np.nan,'ibi_rmssd':np.nan}\n",
    "    sdnn = np.std(arr, ddof=1)\n",
    "    rmssd = np.sqrt(np.mean(np.diff(arr)**2)) if len(arr)>1 else np.nan\n",
    "    return {'ibi_count':len(arr),'ibi_sdnn':sdnn,'ibi_rmssd':rmssd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a543a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_window_features(window_starts, resampled, fs=10.0, win=5.0):\n",
    "    rows = []\n",
    "    for s in window_starts:\n",
    "        e = s+win\n",
    "        row = {'window_start':s,'window_end':e,'window_center':s+win/2}\n",
    "\n",
    "        # EDA\n",
    "        for side in ['left_eda','right_eda']:\n",
    "            if side in resampled:\n",
    "                seg = resampled[side].loc[(resampled[side].index>=s)&(resampled[side].index<e)]\n",
    "                if seg.shape[0]>0:\n",
    "                    vals = seg.iloc[:,0].values\n",
    "                    row[f\"{side}_mean\"] = np.nanmean(vals)\n",
    "                    row[f\"{side}_std\"] = np.nanstd(vals)\n",
    "                    try:\n",
    "                        pks,_ = find_peaks(vals,height=np.nanmean(vals)+0.5*np.nanstd(vals))\n",
    "                        row[f\"{side}_n_peaks\"] = len(pks)\n",
    "                    except: row[f\"{side}_n_peaks\"]=0\n",
    "                else:\n",
    "                    row[f\"{side}_mean\"] = np.nan\n",
    "                    row[f\"{side}_std\"] = np.nan\n",
    "                    row[f\"{side}_n_peaks\"]=0\n",
    "\n",
    "        # BVP -> HR\n",
    "        for side in ['left_bvp','right_bvp']:\n",
    "            if side in resampled:\n",
    "                seg = resampled[side].loc[(resampled[side].index>=s)&(resampled[side].index<e)]\n",
    "                if seg.shape[0]>3:\n",
    "                    vals = seg.iloc[:,0].values\n",
    "                    try:\n",
    "                        pks,_ = find_peaks(vals,distance=int(fs*0.4))\n",
    "                        if len(pks)>=2:\n",
    "                            idxs = seg.index.values\n",
    "                            mean_dt = np.nanmean(np.diff(idxs)) if len(idxs)>1 else 1/fs\n",
    "                            rr = np.diff(pks)*mean_dt\n",
    "                            hr = 60.0/rr\n",
    "                            row[f\"{side}_hr_mean\"]=np.nanmean(hr)\n",
    "                            row[f\"{side}_hr_std\"]=np.nanstd(hr)\n",
    "                            row[f\"{side}_n_beats\"]=len(pks)\n",
    "                        else:\n",
    "                            row[f\"{side}_hr_mean\"]=np.nan\n",
    "                            row[f\"{side}_hr_std\"]=np.nan\n",
    "                            row[f\"{side}_n_beats\"]=len(pks)\n",
    "                    except:\n",
    "                        row[f\"{side}_hr_mean\"]=np.nan\n",
    "                        row[f\"{side}_hr_std\"]=np.nan\n",
    "                        row[f\"{side}_n_beats\"]=0\n",
    "                else:\n",
    "                    row[f\"{side}_hr_mean\"]=np.nan\n",
    "                    row[f\"{side}_hr_std\"]=np.nan\n",
    "                    row[f\"{side}_n_beats\"]=0\n",
    "\n",
    "        # ACC\n",
    "        for side in ['left_acc','right_acc']:\n",
    "            if side in resampled:\n",
    "                seg = resampled[side].loc[(resampled[side].index>=s)&(resampled[side].index<e)]\n",
    "                if seg.shape[0]>0:\n",
    "                    mag = acc_magnitude(seg)\n",
    "                    row[f\"{side}_mag_mean\"]=np.nanmean(mag)\n",
    "                    row[f\"{side}_mag_std\"]=np.nanstd(mag)\n",
    "                    row[f\"{side}_mag_iqr\"]=iqr(mag) if len(mag)>0 else np.nan\n",
    "                else:\n",
    "                    row[f\"{side}_mag_mean\"]=np.nan\n",
    "                    row[f\"{side}_mag_std\"]=np.nan\n",
    "                    row[f\"{side}_mag_iqr\"]=np.nan\n",
    "\n",
    "        # TEMP\n",
    "        for side in ['left_temp','right_temp']:\n",
    "            if side in resampled:\n",
    "                seg = resampled[side].loc[(resampled[side].index>=s)&(resampled[side].index<e)]\n",
    "                if seg.shape[0]>0:\n",
    "                    col = seg.columns[0]\n",
    "                    row[f\"{side}_mean\"]=np.nanmean(seg[col].values)\n",
    "                    row[f\"{side}_std\"]=np.nanstd(seg[col].values)\n",
    "                else:\n",
    "                    row[f\"{side}_mean\"]=np.nan\n",
    "                    row[f\"{side}_std\"]=np.nan\n",
    "\n",
    "        # IBI\n",
    "        for side in ['left_ibi','right_ibi']:\n",
    "            if side in resampled:\n",
    "                ibi_seg = resampled[side].loc[(resampled[side].index>=s)&(resampled[side].index<e)]\n",
    "                if ibi_seg.shape[0]>0:\n",
    "                    h = ibi_features(ibi_seg)\n",
    "                    row.update({f\"{side}_{k}\":v for k,v in h.items()})\n",
    "                else:\n",
    "                    row[f\"{side}_ibi_count\"]=0\n",
    "                    row[f\"{side}_ibi_sdnn\"]=np.nan\n",
    "                    row[f\"{side}_ibi_rmssd\"]=np.nan\n",
    "\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309a33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Participant processing ----------\n",
    "def process_participant(participant_folder, common_fs=10.0, win_s=5.0, step_s=2.5):\n",
    "    print(\"Processing:\", participant_folder.name)\n",
    "    behavior_df = load_behavior(participant_folder)\n",
    "    tags = get_session_tags(participant_folder)\n",
    "    events = parse_behavior_events(behavior_df, tags, participant_folder.parent.name)\n",
    "\n",
    "    # Load Empatica signals\n",
    "    signals = {}\n",
    "    for side in ['Left','Right']:\n",
    "        for kind in ['ACC','BVP','EDA','HR','IBI','TEMP']:\n",
    "            p = participant_folder / f\"{side}_{kind}.csv\"\n",
    "            if p.exists():\n",
    "                try:\n",
    "                    signals[f\"{side.lower()}_{kind.lower()}\"] = load_empatica_file(p, kind.lower())\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning loading {p.name}: {e}\")\n",
    "\n",
    "    # Time range\n",
    "    t_mins = [df.index.min() for df in signals.values()]\n",
    "    t_maxs = [df.index.max() for df in signals.values()]\n",
    "    overall_min = min([t for t in t_mins if pd.notna(t)])\n",
    "    overall_max = max([t for t in t_maxs if pd.notna(t)])\n",
    "\n",
    "    window_starts = np.arange(overall_min, overall_max - win_s, step_s)\n",
    "    feats = extract_window_features(window_starts, signals, fs=common_fs, win=win_s)\n",
    "    feats['participant'] = participant_folder.name\n",
    "\n",
    "    # Behavior per window\n",
    "    feats['n_events_in_window'] = 0\n",
    "    feats['mean_RT'] = np.nan\n",
    "    feats['prop_correct'] = np.nan\n",
    "    feats['session_type'] = None\n",
    "    for idx, win in feats.iterrows():\n",
    "        s, e = win['window_start'], win['window_end']\n",
    "        evs = events[(events['event_time_s']>=s)&(events['event_time_s']<e)]\n",
    "        feats.at[idx,'n_events_in_window'] = len(evs)\n",
    "        if len(evs)>0:\n",
    "            rts = evs['RT_s'].dropna().values\n",
    "            feats.at[idx,'mean_RT'] = np.nanmean(rts) if len(rts)>0 else np.nan\n",
    "            accs = evs['ACC'].dropna().values\n",
    "            feats.at[idx,'prop_correct'] = np.nanmean((accs==1).astype(float)) if len(accs)>0 else np.nan\n",
    "            if 'session_type' in evs.columns:\n",
    "                st_series = evs['session_type'].dropna()\n",
    "                feats.at[idx,'session_type'] = st_series.mode().iloc[0] if len(st_series)>0 else None\n",
    "\n",
    "    return {'participant': participant_folder.name,'features':feats,'events':events,'resampled':signals}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a0d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Experiment processing ----------\n",
    "def process_experiment(exp_folder, out_dir=OUT_DIR, participants=None):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    results = {}\n",
    "    all_feats = []\n",
    "\n",
    "    for sub in sorted(exp_folder.iterdir()):\n",
    "        if not sub.is_dir(): continue\n",
    "        if participants and sub.name not in participants: continue\n",
    "        try:\n",
    "            res = process_participant(sub)\n",
    "            results[sub.name] = res\n",
    "            all_feats.append(res['features'])\n",
    "            # Save per participant\n",
    "            res['features'].to_parquet(out_dir/f\"{sub.name}_features.parquet\")\n",
    "            res['events'].to_csv(out_dir/f\"{sub.name}_events.csv\", index=False)\n",
    "            print(f\"Saved {sub.name} features/events\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed {sub.name}: {e}\")\n",
    "\n",
    "    # Combine all features\n",
    "    if len(all_feats)>0:\n",
    "        combined = pd.concat(all_feats, ignore_index=True)\n",
    "        combined.to_parquet(out_dir/f\"{exp_folder.name}_all_features.parquet\")\n",
    "        combined.to_csv(out_dir/f\"{exp_folder.name}_all_features.csv\", index=False)\n",
    "        return combined, results\n",
    "    else:\n",
    "        return pd.DataFrame(), results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a31151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: A1\n",
      "Saved A1 features/events\n",
      "Processing: A10\n",
      "Saved A10 features/events\n",
      "Processing: A2\n",
      "Saved A2 features/events\n",
      "Processing: A3\n",
      "Saved A3 features/events\n",
      "Processing: A4\n",
      "Saved A4 features/events\n",
      "Processing: A5\n",
      "Saved A5 features/events\n",
      "Processing: A6\n",
      "Saved A6 features/events\n",
      "Processing: A7\n",
      "Saved A7 features/events\n",
      "Processing: A8\n",
      "Saved A8 features/events\n",
      "Processing: A9\n",
      "Saved A9 features/events\n",
      "Processing: Excluded_ID_10\n",
      "Saved Excluded_ID_10 features/events\n",
      "Processing: Excluded_ID_13\n",
      "Saved Excluded_ID_13 features/events\n",
      "Processing: Excluded_ID_5\n",
      "Saved Excluded_ID_5 features/events\n",
      "Processing: Excluded_ID_7\n",
      "Saved Excluded_ID_7 features/events\n",
      "Processing: Excluded_ID_9\n",
      "Saved Excluded_ID_9 features/events\n",
      "Processing: B1\n",
      "Saved B1 features/events\n",
      "Processing: B10\n",
      "Saved B10 features/events\n",
      "Processing: B2\n",
      "Saved B2 features/events\n",
      "Processing: B3\n",
      "Saved B3 features/events\n",
      "Processing: B4\n",
      "Saved B4 features/events\n",
      "Processing: B5\n",
      "Saved B5 features/events\n",
      "Processing: B6\n",
      "Saved B6 features/events\n",
      "Processing: B7\n",
      "Saved B7 features/events\n",
      "Processing: B8\n",
      "Saved B8 features/events\n",
      "Processing: B9\n",
      "Saved B9 features/events\n",
      "Processing: Excluded_ID_1\n",
      "Saved Excluded_ID_1 features/events\n",
      "Processing: Excluded_ID_10\n",
      "Saved Excluded_ID_10 features/events\n",
      "Processing: Excluded_ID_4\n",
      "Saved Excluded_ID_4 features/events\n",
      "All done. Saved combined features to: C:\\Users\\Kavisha\\OneDrive - Johns Hopkins\\EN.585.771_BME_DATASCIENCE\\Capstone_Project\\Data\\Brain_Cognitive_States_Data\\processed_features_final\n"
     ]
    }
   ],
   "source": [
    "# ---------- Run for both experiments ----------\n",
    "exp1_feats, exp1_res = process_experiment(EXP1)\n",
    "exp2_feats, exp2_res = process_experiment(EXP2)\n",
    "full_df = pd.concat([exp1_feats, exp2_feats], ignore_index=True)\n",
    "full_df.to_parquet(OUT_DIR/\"all_participants_features.parquet\")\n",
    "full_df.to_csv(OUT_DIR/\"all_participants_features.csv\", index=False)\n",
    "print(\"All done. Saved combined features to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac5f73b",
   "metadata": {},
   "source": [
    "Final processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a92a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (60602, 36)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataset shape:\", full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee9669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "window_start",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "window_end",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "window_center",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_eda_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_eda_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_eda_n_peaks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "right_eda_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_eda_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_eda_n_peaks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "left_bvp_hr_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_bvp_hr_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_bvp_n_beats",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "right_bvp_hr_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_bvp_hr_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_bvp_n_beats",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "left_acc_mag_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_acc_mag_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_acc_mag_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_acc_mag_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_acc_mag_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_acc_mag_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_temp_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_temp_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_temp_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_temp_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_ibi_ibi_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "left_ibi_ibi_sdnn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "left_ibi_ibi_rmssd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_ibi_ibi_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "right_ibi_ibi_sdnn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "right_ibi_ibi_rmssd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "participant",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_events_in_window",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_RT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prop_correct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "session_type",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "fca37dd1-3fdd-420d-9dfe-bac2c05327b2",
       "rows": [
        [
         "0",
         "1624262175.0",
         "1624262180.0",
         "1624262177.5",
         "0.35708575",
         "0.11053752162058292",
         "0",
         "0.4596760000000001",
         "0.10830824751698277",
         "1",
         "99.18550106609808",
         "27.735170677155416",
         "5",
         "233.56563729146106",
         "157.92414777833324",
         "11",
         "66.27780273752946",
         "0.9313686802052248",
         "0.7991103750510717",
         "63.49215815278136",
         "1.5738815400781399",
         "1.8323760217301412",
         "32.790000000000006",
         "7.105427357601002e-15",
         "33.370000000000005",
         "0.024494897427830387",
         "0",
         null,
         null,
         "0",
         null,
         null,
         "A1",
         "0",
         null,
         null,
         null
        ],
        [
         "1",
         "1624262177.5",
         "1624262182.5",
         "1624262180.0",
         "0.39947905",
         "0.01689257136280619",
         "1",
         "0.4794642500000001",
         "0.01671562850411255",
         "1",
         "156.07403957417512",
         "75.35229199923171",
         "10",
         "311.67953785345094",
         "145.67876758671906",
         "17",
         "66.43986184681084",
         "3.1604600577585793",
         "1.378420957249432",
         "63.90891474311204",
         "7.266403261424109",
         "3.0722714308821537",
         "32.782",
         "0.013266499161420673",
         "33.34400000000001",
         "0.019078784028338916",
         "0",
         null,
         null,
         "0",
         null,
         null,
         "A1",
         "0",
         null,
         null,
         null
        ],
        [
         "2",
         "1624262180.0",
         "1624262185.0",
         "1624262182.5",
         "0.36481695",
         "0.04223614304061747",
         "1",
         "0.49790755",
         "0.0335138382694",
         "2",
         "263.71162545318936",
         "137.25242951076177",
         "14",
         "293.85758998035215",
         "150.94616499296902",
         "16",
         "66.51767888034237",
         "4.65009638304988",
         "2.716899165769206",
         "64.76055966193653",
         "9.09161219326685",
         "6.078635212234516",
         "32.766",
         "0.014966629547095827",
         "33.342000000000006",
         "0.014696938456698467",
         "0",
         null,
         null,
         "0",
         null,
         null,
         "A1",
         "0",
         null,
         null,
         null
        ],
        [
         "3",
         "1624262182.5",
         "1624262187.5",
         "1624262185.0",
         "0.34559590000000007",
         "0.03836773703764662",
         "1",
         "0.5393410999999999",
         "0.020404112719988585",
         "1",
         "265.64166766719956",
         "149.79244971180586",
         "15",
         "223.1004647069556",
         "120.46401302560169",
         "13",
         "66.20211626804137",
         "8.303526457640297",
         "4.783865547688734",
         "64.44203179518502",
         "6.86108869701917",
         "3.9046880660117083",
         "32.75599999999999",
         "0.01562049935181575",
         "33.342000000000006",
         "0.009797958971131634",
         "0",
         null,
         null,
         "0",
         null,
         null,
         "A1",
         "0",
         null,
         null,
         null
        ],
        [
         "4",
         "1624262185.0",
         "1624262190.0",
         "1624262187.5",
         "0.32291505000000004",
         "0.05656373083122701",
         "1",
         "0.5574003000000001",
         "0.02486061407749213",
         "1",
         "228.57039419840083",
         "93.95284351367627",
         "14",
         "222.93989523726182",
         "81.23338894747427",
         "16",
         "65.65871301407353",
         "10.818486739629135",
         "7.080420178653597",
         "63.70739845689345",
         "5.953875364383226",
         "2.256032522241206",
         "32.758",
         "0.0160000000000025",
         "33.33600000000001",
         "0.004898979485568862",
         "0",
         null,
         null,
         "0",
         null,
         null,
         "A1",
         "0",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 36,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>window_center</th>\n",
       "      <th>left_eda_mean</th>\n",
       "      <th>left_eda_std</th>\n",
       "      <th>left_eda_n_peaks</th>\n",
       "      <th>right_eda_mean</th>\n",
       "      <th>right_eda_std</th>\n",
       "      <th>right_eda_n_peaks</th>\n",
       "      <th>left_bvp_hr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>left_ibi_ibi_sdnn</th>\n",
       "      <th>left_ibi_ibi_rmssd</th>\n",
       "      <th>right_ibi_ibi_count</th>\n",
       "      <th>right_ibi_ibi_sdnn</th>\n",
       "      <th>right_ibi_ibi_rmssd</th>\n",
       "      <th>participant</th>\n",
       "      <th>n_events_in_window</th>\n",
       "      <th>mean_RT</th>\n",
       "      <th>prop_correct</th>\n",
       "      <th>session_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459676</td>\n",
       "      <td>0.108308</td>\n",
       "      <td>1</td>\n",
       "      <td>99.185501</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>0.399479</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>1</td>\n",
       "      <td>0.479464</td>\n",
       "      <td>0.016716</td>\n",
       "      <td>1</td>\n",
       "      <td>156.074040</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>0.364817</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497908</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>2</td>\n",
       "      <td>263.711625</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>0.345596</td>\n",
       "      <td>0.038368</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539341</td>\n",
       "      <td>0.020404</td>\n",
       "      <td>1</td>\n",
       "      <td>265.641668</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>1.624262e+09</td>\n",
       "      <td>0.322915</td>\n",
       "      <td>0.056564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>1</td>\n",
       "      <td>228.570394</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_start    window_end  window_center  left_eda_mean  left_eda_std  \\\n",
       "0  1.624262e+09  1.624262e+09   1.624262e+09       0.357086      0.110538   \n",
       "1  1.624262e+09  1.624262e+09   1.624262e+09       0.399479      0.016893   \n",
       "2  1.624262e+09  1.624262e+09   1.624262e+09       0.364817      0.042236   \n",
       "3  1.624262e+09  1.624262e+09   1.624262e+09       0.345596      0.038368   \n",
       "4  1.624262e+09  1.624262e+09   1.624262e+09       0.322915      0.056564   \n",
       "\n",
       "   left_eda_n_peaks  right_eda_mean  right_eda_std  right_eda_n_peaks  \\\n",
       "0                 0        0.459676       0.108308                  1   \n",
       "1                 1        0.479464       0.016716                  1   \n",
       "2                 1        0.497908       0.033514                  2   \n",
       "3                 1        0.539341       0.020404                  1   \n",
       "4                 1        0.557400       0.024861                  1   \n",
       "\n",
       "   left_bvp_hr_mean  ...  left_ibi_ibi_sdnn  left_ibi_ibi_rmssd  \\\n",
       "0         99.185501  ...                NaN                 NaN   \n",
       "1        156.074040  ...                NaN                 NaN   \n",
       "2        263.711625  ...                NaN                 NaN   \n",
       "3        265.641668  ...                NaN                 NaN   \n",
       "4        228.570394  ...                NaN                 NaN   \n",
       "\n",
       "   right_ibi_ibi_count  right_ibi_ibi_sdnn  right_ibi_ibi_rmssd  participant  \\\n",
       "0                    0                 NaN                  NaN           A1   \n",
       "1                    0                 NaN                  NaN           A1   \n",
       "2                    0                 NaN                  NaN           A1   \n",
       "3                    0                 NaN                  NaN           A1   \n",
       "4                    0                 NaN                  NaN           A1   \n",
       "\n",
       "   n_events_in_window  mean_RT  prop_correct  session_type  \n",
       "0                   0      NaN           NaN          None  \n",
       "1                   0      NaN           NaN          None  \n",
       "2                   0      NaN           NaN          None  \n",
       "3                   0      NaN           NaN          None  \n",
       "4                   0      NaN           NaN          None  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd032827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'window_end', 'window_center', 'left_eda_mean',\n",
      "       'left_eda_std', 'left_eda_n_peaks', 'right_eda_mean', 'right_eda_std',\n",
      "       'right_eda_n_peaks', 'left_bvp_hr_mean', 'left_bvp_hr_std',\n",
      "       'left_bvp_n_beats', 'right_bvp_hr_mean', 'right_bvp_hr_std',\n",
      "       'right_bvp_n_beats', 'left_acc_mag_mean', 'left_acc_mag_std',\n",
      "       'left_acc_mag_iqr', 'right_acc_mag_mean', 'right_acc_mag_std',\n",
      "       'right_acc_mag_iqr', 'left_temp_mean', 'left_temp_std',\n",
      "       'right_temp_mean', 'right_temp_std', 'left_ibi_ibi_count',\n",
      "       'left_ibi_ibi_sdnn', 'left_ibi_ibi_rmssd', 'right_ibi_ibi_count',\n",
      "       'right_ibi_ibi_sdnn', 'right_ibi_ibi_rmssd', 'participant',\n",
      "       'n_events_in_window', 'mean_RT', 'prop_correct', 'session_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Show all column names\n",
    "print(full_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ee940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
